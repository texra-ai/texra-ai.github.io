<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>AI Models | TeXRA</title>
    <meta name="description" content="Your Intelligent Academic Research Assistant">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.QcnRD2bl.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.CeP0zZ9T.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.fkSL6LTs.js">
    <link rel="modulepreload" href="/assets/chunks/theme.BmEYLwtb.js">
    <link rel="modulepreload" href="/assets/chunks/katex.ChWnQ-fc.js">
    <link rel="modulepreload" href="/assets/chunks/dagre-OKDRZEBW.urOWykwa.js">
    <link rel="modulepreload" href="/assets/chunks/c4Diagram-VJAJSXHY.DslN4gCG.js">
    <link rel="modulepreload" href="/assets/chunks/flowDiagram-4HSFHLVR.DhIG6eVF.js">
    <link rel="modulepreload" href="/assets/chunks/erDiagram-Q7BY3M3F.DDisuin_.js">
    <link rel="modulepreload" href="/assets/chunks/gitGraphDiagram-7IBYFJ6S.D9tbvf3G.js">
    <link rel="modulepreload" href="/assets/chunks/ganttDiagram-APWFNJXF.lmJW4i8n.js">
    <link rel="modulepreload" href="/assets/chunks/infoDiagram-PH2N3AL5.DMqwvp77.js">
    <link rel="modulepreload" href="/assets/chunks/pieDiagram-IB7DONF6.G8E97_q0.js">
    <link rel="modulepreload" href="/assets/chunks/quadrantDiagram-7GDLP6J5.CacouFKM.js">
    <link rel="modulepreload" href="/assets/chunks/xychartDiagram-VJFVF3MP.CYRVp1rK.js">
    <link rel="modulepreload" href="/assets/chunks/requirementDiagram-KVF5MWMF.BXw8D9hE.js">
    <link rel="modulepreload" href="/assets/chunks/sequenceDiagram-X6HHIX6F.BECVc2Z3.js">
    <link rel="modulepreload" href="/assets/chunks/classDiagram-GIVACNV2.Biy1fc3x.js">
    <link rel="modulepreload" href="/assets/chunks/classDiagram-v2-COTLJTTW.Biy1fc3x.js">
    <link rel="modulepreload" href="/assets/chunks/stateDiagram-DGXRK772.BsFzQGsV.js">
    <link rel="modulepreload" href="/assets/chunks/stateDiagram-v2-YXO3MK2T.D4axIWkA.js">
    <link rel="modulepreload" href="/assets/chunks/journeyDiagram-U35MCT3I.DQG3M5gu.js">
    <link rel="modulepreload" href="/assets/chunks/timeline-definition-BDJGKUSR.DTbqwZZv.js">
    <link rel="modulepreload" href="/assets/chunks/mindmap-definition-ALO5MXBD.CmCZBDwn.js">
    <link rel="modulepreload" href="/assets/chunks/kanban-definition-NDS4AKOZ.BmQ7qnBo.js">
    <link rel="modulepreload" href="/assets/chunks/sankeyDiagram-QLVOVGJD.Bs2cB2au.js">
    <link rel="modulepreload" href="/assets/chunks/diagram-VNBRO52H.B0v0UQ-F.js">
    <link rel="modulepreload" href="/assets/chunks/diagram-SSKATNLV.C3X446Wc.js">
    <link rel="modulepreload" href="/assets/chunks/blockDiagram-JOT3LUYC.DDSZ4d8o.js">
    <link rel="modulepreload" href="/assets/chunks/architectureDiagram-IEHRJDOE.G6deJk-U.js">
    <link rel="modulepreload" href="/assets/chunks/virtual_mermaid-config.DDnGl6nM.js">
    <link rel="modulepreload" href="/assets/guide_models.md.DULKK3YG.lean.js">
    <link rel="icon" href="/logo-128x128.svg">
    <link rel="stylesheet" href="/assets/fonts/codicon/codicon.css">
    <script>document.addEventListener("DOMContentLoaded",function(){"scrollRestoration"in history&&(history.scrollRestoration="manual"),setTimeout(function(){function r(){const t=document.querySelectorAll(".pdf-tab"),e=document.getElementById("pdf-frame"),c=document.getElementById("pdf-link");if(!t.length||!e||!c)return;t.forEach(o=>{o.replaceWith(o.cloneNode(!0))});const s=document.querySelectorAll(".pdf-tab");s.forEach(o=>{o.addEventListener("click",function(i){i.preventDefault(),i.stopPropagation();const l=window.scrollY||document.documentElement.scrollTop,n=this.getAttribute("data-pdf");if(n)return e.src=n,c.href=n,s.forEach(d=>d.classList.remove("active")),this.classList.add("active"),setTimeout(()=>{window.scrollTo(0,l)},0),console.log("Tab clicked:",n),!1})})}if(r(),setTimeout(r,1e3),window.addEventListener){let t=location.href;new MutationObserver(()=>{const e=location.href;e!==t&&(t=e,setTimeout(r,500))}).observe(document,{subtree:!0,childList:!0})}},200)});</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/" data-v-9f43907a><!--[--><!--]--><!--[--><img class="VPImage logo" src="/logo-128x128.svg" alt data-v-ab19afbb><!--]--><span data-v-9f43907a>TeXRA</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/guide/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Guide</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/launch.html" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Launch</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/reference/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Reference</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://github.com/texra-ai/texra-issues" target="_blank" rel="noreferrer" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>GitHub</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/texra-ai" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><!----><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/texra-ai" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Getting Started</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Introduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/installation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Installation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/quick-start.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Quick Start</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/latex-compilation.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>LaTeX Compilation Setup</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/acknowledgments.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Acknowledgments & Inspirations</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Core Concepts</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/agent-architecture.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Agent Architecture</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/built-in-agents.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Built-in Agents</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/models.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/file-management.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>File Management</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/working-with-figures.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Working with Figures</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/progress-board.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>ProgressBoard</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/tool-integration.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Tool Integration</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Advanced Usage</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/tikz-figures.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>TikZ Figures</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/latex-diff.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>LaTeX Diff</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/intelligent-merge.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Intelligent Merge</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/multiple-output.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Multiple Output</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Customization</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/configuration.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Configuration</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/agent-explorer.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Agent Explorer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/custom-agents.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>Custom Agents</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0" data-v-51288d80 data-v-0009425e><div class="item" role="button" tabindex="0" data-v-0009425e><div class="indicator" data-v-0009425e></div><h2 class="text" data-v-0009425e>Best Practices</h2><!----></div><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/guide/best-practices.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>General Workflow</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _guide_models" data-v-e6f2a212><div><h1 id="ai-models" tabindex="-1">AI Models <a class="header-anchor" href="#ai-models" aria-label="Permalink to &quot;AI Models&quot;">​</a></h1><p>TeXRA supports a variety of language models from different providers, allowing you to choose the best fit for your task&#39;s complexity, required speed, and budget (think of it as choosing your research assistant&#39;s brain!). This guide provides an overview of the models available by default.</p><h2 id="model-providers-overview" tabindex="-1">Model Providers Overview <a class="header-anchor" href="#model-providers-overview" aria-label="Permalink to &quot;Model Providers Overview&quot;">​</a></h2><p>TeXRA primarily integrates with models from:</p><ol><li><strong>Anthropic</strong> (Claude family)</li><li><strong>OpenAI</strong> (GPT and O-series families)</li><li><strong>Google</strong> (Gemini family)</li><li><strong>Other Providers</strong> (via OpenRouter, including Grok, DeepSeek)</li></ol><p>You can select the desired model from the dropdown list in the TeXRA UI. Hovering over an option shows its provider, context window, and estimated cost.</p><h2 id="default-model-selection" tabindex="-1">Default Model Selection <a class="header-anchor" href="#default-model-selection" aria-label="Permalink to &quot;Default Model Selection&quot;">​</a></h2><p>Here&#39;s a quick comparison of the models available by default in TeXRA:</p><h3 id="anthropic-models" tabindex="-1">Anthropic Models <a class="header-anchor" href="#anthropic-models" aria-label="Permalink to &quot;Anthropic Models&quot;">​</a></h3><p>Known for strong instruction following and context handling.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>opus41T</code></td><td style="text-align:left;">Latest Opus with explicit reasoning steps</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;">Claude 4.1 Opus with thinking</td></tr><tr><td style="text-align:left;"><code>opus41</code></td><td style="text-align:left;">Latest high quality, complex tasks</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;">Claude 4.1 Opus</td></tr><tr><td style="text-align:left;"><code>opus4T</code></td><td style="text-align:left;">Opus 4 with explicit reasoning steps</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;">Claude 4 Opus with thinking</td></tr><tr><td style="text-align:left;"><code>opus4</code></td><td style="text-align:left;">Opus 4 high quality, complex tasks</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;">Claude 4 Opus</td></tr><tr><td style="text-align:left;"><code>sonnet4T</code></td><td style="text-align:left;">Latest Sonnet with explicit reasoning steps</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Claude 4 Sonnet with thinking</td></tr><tr><td style="text-align:left;"><code>sonnet4</code></td><td style="text-align:left;">Latest strong all-rounder</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Claude 4 Sonnet</td></tr><tr><td style="text-align:left;"><code>sonnet37T</code></td><td style="text-align:left;"><code>sonnet37</code> with explicit reasoning steps</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Good for math, complex logic</td></tr><tr><td style="text-align:left;"><code>sonnet37</code></td><td style="text-align:left;">Strong all-rounder, good context</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>sonnet35</code></td><td style="text-align:left;">Good balance of quality/cost (older Sonnet)</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr></tbody></table><h4 id="sonnet-4-1m-context-beta" tabindex="-1">Sonnet 4 1M Context (Beta) <a class="header-anchor" href="#sonnet-4-1m-context-beta" aria-label="Permalink to &quot;Sonnet 4 1M Context (Beta)&quot;">​</a></h4><p>To experiment with Anthropic&#39;s 1M-token context window for Sonnet 4, enable <code>&quot;texra.model.useAnthropic1MBeta&quot;: true</code> in VS Code settings. The extension attaches the <code>context-1m-2025-08-07</code> beta header for these requests. Only Sonnet 4 supports this beta, and TeXRA still enforces the tier‑4 limit of 200 K tokens.</p><h3 id="openai-models" tabindex="-1">OpenAI Models <a class="header-anchor" href="#openai-models" aria-label="Permalink to &quot;OpenAI Models&quot;">​</a></h3><p>Known for strong reasoning and creative capabilities.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>o1</code></td><td style="text-align:left;">Advanced reasoning, math, figures</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;">Explicit reasoning</td></tr><tr><td style="text-align:left;"><code>gpt45</code></td><td style="text-align:left;">High quality, vision (Preview)</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>gpt5</code></td><td style="text-align:left;">Flagship reasoning &amp; coding</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">400k context</td></tr><tr><td style="text-align:left;"><code>gpt5-</code></td><td style="text-align:left;">Flagship mini, fast</td><td style="text-align:left;">$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">400k context, mini</td></tr><tr><td style="text-align:left;"><code>gpt5--</code></td><td style="text-align:left;">Flagship nano, fastest</td><td style="text-align:left;">$</td><td style="text-align:left;">Very Fast</td><td style="text-align:left;">400k context, nano</td></tr><tr><td style="text-align:left;"><code>gpt5</code></td><td style="text-align:left;">Flagship reasoning &amp; coding</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">400k context</td></tr><tr><td style="text-align:left;"><code>gpt5-</code></td><td style="text-align:left;">Flagship mini, fast</td><td style="text-align:left;">$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">400k context, mini</td></tr><tr><td style="text-align:left;"><code>gpt5--</code></td><td style="text-align:left;">Flagship nano, fastest</td><td style="text-align:left;">$</td><td style="text-align:left;">Very Fast</td><td style="text-align:left;">400k context, nano</td></tr><tr><td style="text-align:left;"><code>gpt41</code></td><td style="text-align:left;">Long-context vision, powerful</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">1M tokens context</td></tr><tr><td style="text-align:left;"><code>gpt41-</code></td><td style="text-align:left;">Long-context vision, cost-effective</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">1M tokens context, mini</td></tr><tr><td style="text-align:left;"><code>gpt41--</code></td><td style="text-align:left;">Long-context vision, cheapest</td><td style="text-align:left;">$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">1M tokens context, nano</td></tr><tr><td style="text-align:left;"><code>gpt4o</code></td><td style="text-align:left;">Strong all-rounder, vision</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Good default choice</td></tr><tr><td style="text-align:left;"><code>gpt4ol</code></td><td style="text-align:left;">Latest <code>gpt4o</code>, potentially better</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>o3</code></td><td style="text-align:left;">Coding, tool calling</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>o3pro</code></td><td style="text-align:left;">Reliable answers, heavy compute</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Slow</td><td style="text-align:left;"><code>o3-pro</code></td></tr><tr><td style="text-align:left;"><code>o3-</code></td><td style="text-align:left;">Fast reasoning</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;"><code>o3-mini</code></td></tr><tr><td style="text-align:left;"><code>o1-</code></td><td style="text-align:left;">Fast reasoning (smaller <code>o1</code>)</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;"><code>o1-mini</code></td></tr><tr><td style="text-align:left;"><code>gptoss</code></td><td style="text-align:left;">Open-weight reasoning, large context</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"><code>gpt-oss-120b</code> (OpenRouter only)</td></tr><tr><td style="text-align:left;"><code>gptoss-</code></td><td style="text-align:left;">Open-weight reasoning, cost-effective</td><td style="text-align:left;">$</td><td style="text-align:left;">Fast</td><td style="text-align:left;"><code>gpt-oss-20b</code> (OpenRouter only)</td></tr></tbody></table><blockquote><p><strong>Note:</strong> GPT-5 reasoning summaries require additional account verification. TeXRA disables them by default—enable <code>&quot;texra.model.gpt5ReasoningSummary&quot;: true</code> if your account supports this feature. | <code>gptoss</code> | Open-weight reasoning, large context | $$ | Medium | <code>gpt-oss-120b</code> | | <code>gptoss-</code> | Open-weight reasoning, cost-effective | $ | Fast | <code>gpt-oss-20b</code> |</p></blockquote><h3 id="google-models" tabindex="-1">Google Models <a class="header-anchor" href="#google-models" aria-label="Permalink to &quot;Google Models&quot;">​</a></h3><p>Known for large context windows, multimodality, and speed/cost efficiency.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>gemini25p</code></td><td style="text-align:left;">Strong reasoning, vision, large context</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Latest Pro model</td></tr><tr><td style="text-align:left;"><code>gemini2p</code></td><td style="text-align:left;">Good reasoning, vision, very large context</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>gemini25f</code></td><td style="text-align:left;">Fast reasoning, large context</td><td style="text-align:left;">$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">Latest Flash model</td></tr><tr><td style="text-align:left;"><code>gemini2fT</code></td><td style="text-align:left;"><code>gemini2f</code> with explicit reasoning steps</td><td style="text-align:left;">$</td><td style="text-align:left;">Fast</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;"><code>gemini2f</code></td><td style="text-align:left;">Fastest, most cost-effective, vision</td><td style="text-align:left;">$</td><td style="text-align:left;">Very Fast</td><td style="text-align:left;">Good for simple tasks, native PDF/audio</td></tr></tbody></table><h3 id="deepseek-models" tabindex="-1">DeepSeek Models <a class="header-anchor" href="#deepseek-models" aria-label="Permalink to &quot;DeepSeek Models&quot;">​</a></h3><p>Strong technical and coding performance, cost-effective. DeepSeek&#39;s API now supports function calling so agents can use external tools during a run.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>dsv3</code></td><td style="text-align:left;">Good coding &amp; general tasks</td><td style="text-align:left;">$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">DeepSeek V3 Chat</td></tr><tr><td style="text-align:left;"><code>dsr1</code></td><td style="text-align:left;">Advanced reasoning</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">DeepSeek R1</td></tr></tbody></table><h3 id="moonshot-kimi-models" tabindex="-1">Moonshot Kimi Models <a class="header-anchor" href="#moonshot-kimi-models" aria-label="Permalink to &quot;Moonshot Kimi Models&quot;">​</a></h3><p>High context models from Moonshot, suitable for complex reasoning and large documents.</p><p><strong>Kimi K2</strong> is Moonshot&#39;s open-source 1T‑parameter MoE model (32B active). It excels at coding and agentic tasks but currently lacks multimodal and thought-mode support. The 0905 preview offers a 256k context window, and a high-speed turbo variant is also available.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>kimit</code></td><td style="text-align:left;">Detailed reasoning with vision</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Kimi Thinking Preview</td></tr><tr><td style="text-align:left;"><code>kimi</code></td><td style="text-align:left;">Large context, general tasks</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">128k context</td></tr><tr><td style="text-align:left;"><code>kimiv</code></td><td style="text-align:left;">Vision-enabled variant</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">128k context, vision</td></tr><tr><td style="text-align:left;"><code>kimi2</code></td><td style="text-align:left;">Agent tasks, 256k context</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Kimi K2 0905 Preview (<code>moonshotai/kimi-k2-0905</code>)</td></tr><tr><td style="text-align:left;"><code>kimi2turbo</code></td><td style="text-align:left;">Fast agent tasks</td><td style="text-align:left;">$$$$</td><td style="text-align:left;">Very Fast</td><td style="text-align:left;">Kimi K2 Turbo Preview (<code>moonshotai/kimi-k2-turbo</code>)</td></tr></tbody></table><p>The earlier Kimi K2 0711 model remains available on OpenRouter as <code>moonshotai/kimi-k2</code>.</p><p>Additional resources: <a href="https://platform.moonshot.ai" target="_blank" rel="noreferrer">API</a> – $0.15/million input tokens (cache hit), $0.60/million input tokens (cache miss), $2.50/million output tokens. <a href="https://moonshotai.github.io/Kimi-K2/" target="_blank" rel="noreferrer">Tech blog</a>, <a href="https://huggingface.co/moonshotai" target="_blank" rel="noreferrer">Weights &amp; code</a>, <a href="https://github.com/MoonshotAI/Kimi-K2" target="_blank" rel="noreferrer">GitHub</a>.</p><h3 id="dashscope-qwen-models" tabindex="-1">DashScope Qwen Models <a class="header-anchor" href="#dashscope-qwen-models" aria-label="Permalink to &quot;DashScope Qwen Models&quot;">​</a></h3><p>Cost-effective models from Alibaba with strong multilingual capabilities.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>qwen3max</code></td><td style="text-align:left;">Best-in-class reasoning, 256k ctx</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Qwen3 Max, no deep thinking</td></tr><tr><td style="text-align:left;"><code>qwenplus</code></td><td style="text-align:left;">Hybrid reasoning, 1M ctx</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Qwen3 Plus, enable_thinking</td></tr><tr><td style="text-align:left;"><code>qwenturbo</code></td><td style="text-align:left;">Fast responses with optional thinking mode</td><td style="text-align:left;">$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">Qwen Turbo, enable_thinking</td></tr></tbody></table><p>Deep thinking models first stream their reasoning before the final answer. <code>qwenplus</code> and <code>qwenturbo</code> support this mode. Pass <code>enable_thinking: true</code> in the request body to turn it on; commercial tiers disable it by default. <code>qwen3max</code> always runs in non-thinking mode.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">os.getenv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;DASHSCOPE_API_KEY&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://dashscope-intl.aliyuncs.com/compatible-mode/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">resp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;qwen-plus-2025-07-28&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Who are you?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    extra_body</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;enable_thinking&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(resp.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].message.reasoning_content)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(resp.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].message.content)</span></span></code></pre></div><p>Use the <code>thinking_budget</code> parameter to cap how many tokens the reasoning step can consume.</p><h3 id="copilot-models" tabindex="-1">Copilot Models <a class="header-anchor" href="#copilot-models" aria-label="Permalink to &quot;Copilot Models&quot;">​</a></h3><p>GitHub Copilot models are available through VS Code&#39;s built-in Language Model API. These models require user consent and sign in to GitHub Copilot.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>copilot4o</code></td><td style="text-align:left;">Strong all-rounder, vision</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">Uses GPT-4o backend</td></tr></tbody></table><h3 id="grok-xai-models" tabindex="-1">Grok / xAI Models <a class="header-anchor" href="#grok-xai-models" aria-label="Permalink to &quot;Grok / xAI Models&quot;">​</a></h3><p>Large context models from xAI.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th><th style="text-align:left;">Notes</th></tr></thead><tbody><tr><td style="text-align:left;"><code>grok4</code></td><td style="text-align:left;">Very large context, strong reasoning</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">xAI Grok 4</td></tr><tr><td style="text-align:left;"><code>grok3</code></td><td style="text-align:left;">Large context, alternative reasoning</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td><td style="text-align:left;">xAI Grok 3</td></tr><tr><td style="text-align:left;"><code>grok3-</code></td><td style="text-align:left;">Faster Grok 3 (mini)</td><td style="text-align:left;">$$</td><td style="text-align:left;">Fast</td><td style="text-align:left;">xAI Grok 3 Mini</td></tr></tbody></table><h3 id="other-models-available-primarily-via-openrouter" tabindex="-1">Other Models (Available Primarily via OpenRouter) <a class="header-anchor" href="#other-models-available-primarily-via-openrouter" aria-label="Permalink to &quot;Other Models (Available Primarily via OpenRouter)&quot;">​</a></h3><p>These models are generally accessed by enabling OpenRouter in settings.</p><table tabindex="0"><thead><tr><th style="text-align:left;">Model ID</th><th style="text-align:left;">Key Strength / Use Case</th><th style="text-align:left;">Provider</th><th style="text-align:left;">Relative Cost</th><th style="text-align:left;">Relative Speed</th></tr></thead><tbody><tr><td style="text-align:left;"><code>llama31</code></td><td style="text-align:left;">Strong open model, large context</td><td style="text-align:left;">Meta</td><td style="text-align:left;">$$$</td><td style="text-align:left;">Medium</td></tr><tr><td style="text-align:left;"><code>qvq-72b</code></td><td style="text-align:left;">Strong multi-lingual</td><td style="text-align:left;">Qwen/Alibaba</td><td style="text-align:left;">$$</td><td style="text-align:left;">Medium</td></tr></tbody></table><p><em>Relative Cost/Speed are estimates: $ = Low/Fast, $$$$ = High/Slow.</em></p><h2 id="choosing-the-right-model" tabindex="-1">Choosing the Right Model <a class="header-anchor" href="#choosing-the-right-model" aria-label="Permalink to &quot;Choosing the Right Model&quot;">​</a></h2><p>Consider these factors:</p><ul><li><strong>Task Complexity</strong>: Simple corrections might only need a <code>$</code>/Fast model (<code>gemini2f</code>), while complex paper transformations benefit from <code>$$$$</code>/Slow models (<code>opus</code>, <code>o1</code>).</li><li><strong>Budget</strong>: Use cost indicators ($ - $$$$) to guide selection.</li><li><strong>Speed</strong>: If quick turnaround is needed, prefer Fast/Very Fast models.</li><li><strong>Special Capabilities</strong>: Do you need explicit reasoning (<code>sonnet37T</code>, <code>gemini2fT</code>, <code>o1</code>, <code>o3-</code>, <code>o1-</code>, <code>gptoss</code>, <code>gptoss-</code>, <code>dsr1</code>), vision (<code>gpt5</code>, <code>gpt4o</code>, <code>gemini*</code>), native PDF/audio (<code>gemini*</code>), or very large context (<code>gemini*</code>, <code>gpt41</code>, <code>gpt5</code>)?</li></ul><p>Experimentation is often key to finding the best model for your specific needs and writing style.</p><h2 id="model-configuration" tabindex="-1">Model Configuration <a class="header-anchor" href="#model-configuration" aria-label="Permalink to &quot;Model Configuration&quot;">​</a></h2><p>You can customize which models appear in the TeXRA dropdown list via VS Code Settings (<code>Ctrl+,</code>). Search for <code>texra.models</code> and edit the JSON array. Here are the defaults:</p><div class="tip custom-block"><p class="custom-block-title">Model Availability</p><p>The specific models available by default and their identifiers (<code>sonnet37</code>, <code>gpt5</code>, etc.) are maintained by the TeXRA developers and may change in future updates based on new releases and performance evaluations.</p></div><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;texra.models&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;sonnet37T&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;sonnet37&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;o3&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;o4-&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;o3-&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gptoss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gptoss-&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;o1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gpt41&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gpt5&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gpt4o&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gemini25p&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gemini25f&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;gemini2fT&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;dsv3&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;dsr1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;grok4&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;grok3&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;qwenplus&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;kimit&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;kimiv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;kimi2&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;copilot4o&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre></div><h2 id="using-openrouter" tabindex="-1">Using OpenRouter <a class="header-anchor" href="#using-openrouter" aria-label="Permalink to &quot;Using OpenRouter&quot;">​</a></h2><p>To access models not directly integrated (like Llama or Qwen), find alternative pricing, or ensure access if a direct API key isn&#39;t available, you can use <a href="https://openrouter.ai/" target="_blank" rel="noreferrer">OpenRouter</a>.</p><ol><li>Get an <a href="https://openrouter.ai/" target="_blank" rel="noreferrer">OpenRouter</a> API key.</li><li>Add the key using the <code>TeXRA: Set API Key</code> command (select OpenRouter).</li><li>Enable OpenRouter in VS Code Settings: <code>&quot;texra.model.useOpenRouter&quot;: true</code>.</li></ol><p>When enabled, TeXRA will route API calls <strong>for all compatible models</strong> (including Anthropic, OpenAI, Google, DeepSeek, Grok, etc., if supported by OpenRouter) through OpenRouter instead of their direct APIs.</p><h2 id="streaming-support" tabindex="-1">Streaming Support <a class="header-anchor" href="#streaming-support" aria-label="Permalink to &quot;Streaming Support&quot;">​</a></h2><p>For long responses or reasoning-heavy models, you can enable streaming to see incremental results. This is often more robust for complex tasks.</p><p>Configure streaming in VS Code Settings:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// General streaming toggle (applies if specific model type toggle isn&#39;t set)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;texra.model.useStreaming&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Specific toggle for Anthropic reasoning models</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;texra.model.useStreamingAnthropicReasoning&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Specific toggle for OpenAI reasoning models</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;texra.model.useStreamingOpenAIReasoning&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Specific toggle for Google models</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;texra.model.useStreamingGoogle&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// Similar configuration exists for DeepSeek and OpenRouter models</span></span></code></pre></div><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">​</a></h2><ul><li><a href="./built-in-agents.html">Built-in Agents</a>: See which agents work well with different models.</li><li><a href="./configuration.html">Configuration</a>: Learn about other model-related settings like streaming.</li><li><a href="./openai-responses-api.html">OpenAI Responses API</a>: Overview of the new API used when <code>useOpenAIResponsesAPI</code> is enabled.</li></ul></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/guide/built-in-agents.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>Built-in Agents</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/guide/file-management.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>File Management</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-d8b57b2d data-v-566314d4><div class="container" data-v-566314d4><!----><p class="copyright" data-v-566314d4>Copyright © 2024-present TeXRA Team. All rights reserved.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"guide_acknowledgments.md\":\"RU567_mA\",\"guide_agent-architecture.md\":\"CasbZF4H\",\"guide_agent-explorer.md\":\"DnsWcTqo\",\"guide_agents.md\":\"CFZiMBkd\",\"guide_best-practices.md\":\"C8MibtNp\",\"guide_built-in-agents.md\":\"CL_VZQEX\",\"guide_configuration.md\":\"CQjk-w5K\",\"guide_custom-agents.md\":\"EF4BATTM\",\"guide_file-management.md\":\"C2QsKCrG\",\"guide_index.md\":\"DxpEnvis\",\"guide_installation.md\":\"pwF2zMPs\",\"guide_intelligent-merge.md\":\"B97KV5VG\",\"guide_latex-compilation.md\":\"CTuQKhLl\",\"guide_latex-diff.md\":\"DwFsZKsy\",\"guide_models.md\":\"DULKK3YG\",\"guide_multiple-output.md\":\"Cchrn6DA\",\"guide_openai-responses-api.md\":\"Bukbk0E3\",\"guide_progress-board.md\":\"rkx-N52L\",\"guide_quick-start.md\":\"DWQUlXoe\",\"guide_tikz-figures.md\":\"CHbAF2Vg\",\"guide_tool-integration.md\":\"C9o5atpo\",\"guide_working-with-figures.md\":\"CAF8v84T\",\"guide_working-with-overleaf.md\":\"y00tLNlz\",\"index.md\":\"0g_hFbqp\",\"launch.md\":\"Bvci4va2\",\"reference_glossary.md\":\"UKXN7s44\",\"reference_index.md\":\"gf4ABSNk\",\"reference_tool-format.md\":\"BT5DaQLk\",\"reference_troubleshooting.md\":\"DUqv6Cnl\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"TeXRA\",\"description\":\"Your Intelligent Academic Research Assistant\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/logo-128x128.svg\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Guide\",\"link\":\"/guide/\"},{\"text\":\"Launch\",\"link\":\"/launch\"},{\"text\":\"Reference\",\"link\":\"/reference/\"},{\"text\":\"GitHub\",\"link\":\"https://github.com/texra-ai/texra-issues\"}],\"sidebar\":{\"/guide/\":[{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Introduction\",\"link\":\"/guide/\"},{\"text\":\"Installation\",\"link\":\"/guide/installation\"},{\"text\":\"Quick Start\",\"link\":\"/guide/quick-start\"},{\"text\":\"LaTeX Compilation Setup\",\"link\":\"/guide/latex-compilation.md\"},{\"text\":\"Acknowledgments & Inspirations\",\"link\":\"/guide/acknowledgments.md\"}]},{\"text\":\"Core Concepts\",\"items\":[{\"text\":\"Agent Architecture\",\"link\":\"/guide/agent-architecture.md\"},{\"text\":\"Built-in Agents\",\"link\":\"/guide/built-in-agents.md\"},{\"text\":\"Models\",\"link\":\"/guide/models\"},{\"text\":\"File Management\",\"link\":\"/guide/file-management\"},{\"text\":\"Working with Figures\",\"link\":\"/guide/working-with-figures.md\"},{\"text\":\"ProgressBoard\",\"link\":\"/guide/progress-board\"},{\"text\":\"Tool Integration\",\"link\":\"/guide/tool-integration\"}]},{\"text\":\"Advanced Usage\",\"items\":[{\"text\":\"TikZ Figures\",\"link\":\"/guide/tikz-figures\"},{\"text\":\"LaTeX Diff\",\"link\":\"/guide/latex-diff\"},{\"text\":\"Intelligent Merge\",\"link\":\"/guide/intelligent-merge\"},{\"text\":\"Multiple Output\",\"link\":\"/guide/multiple-output\"}]},{\"text\":\"Customization\",\"items\":[{\"text\":\"Configuration\",\"link\":\"/guide/configuration\"},{\"text\":\"Agent Explorer\",\"link\":\"/guide/agent-explorer\"},{\"text\":\"Custom Agents\",\"link\":\"/guide/custom-agents\"}]},{\"text\":\"Best Practices\",\"items\":[{\"text\":\"General Workflow\",\"link\":\"/guide/best-practices.md\"}]}],\"/reference/\":[{\"text\":\"Resources\",\"items\":[{\"text\":\"Troubleshooting\",\"link\":\"/reference/troubleshooting\"},{\"text\":\"Glossary\",\"link\":\"/reference/glossary\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/texra-ai\"}],\"search\":{\"provider\":\"local\"},\"footer\":{\"copyright\":\"Copyright © 2024-present TeXRA Team. All rights reserved.\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>