import{_ as i,c as t,o as a,a6 as o}from"./chunks/framework.fkSL6LTs.js";const s="/images/media-section.png",h=JSON.parse('{"title":"Working with Figures","description":"","frontmatter":{},"headers":[],"relativePath":"guide/working-with-figures.md","filePath":"guide/working-with-figures.md"}'),n={name:"guide/working-with-figures.md"};function r(l,e,c,d,u,p){return a(),t("div",null,e[0]||(e[0]=[o('<h1 id="working-with-figures" tabindex="-1">Working with Figures <a class="header-anchor" href="#working-with-figures" aria-label="Permalink to &quot;Working with Figures&quot;">​</a></h1><p>TeXRA integrates seamlessly with visual and audio media, allowing AI agents to analyze, reference, or even generate figures directly within your documents. This guide covers how to manage media files (your paper&#39;s eye candy!) and leverage automatic extraction features.</p><h2 id="the-media-section-in-texra-ui" tabindex="-1">The &quot;Media&quot; Section in TeXRA UI <a class="header-anchor" href="#the-media-section-in-texra-ui" aria-label="Permalink to &quot;The &quot;Media&quot; Section in TeXRA UI&quot;">​</a></h2><p>The main TeXRA panel includes a dedicated &quot;Media&quot; section for managing relevant files:</p><p><img src="'+s+`" alt="Media Section UI Placeholder"></p><ul><li><strong>Dropdown</strong>: Select a primary media file (image, PDF, audio).</li><li><strong>Multiple Files Toggle (<code>▼</code>)</strong>: Expand to select multiple media files. Useful when an agent needs to analyze several images or audio clips.</li><li><strong>Buttons</strong>: Add (<i class="codicon codicon-add"></i>), Empty Single (<i class="codicon codicon-close"></i>), Empty List (<i class="codicon codicon-trash"></i>) work similarly to other file sections. See <a href="./file-management.html">File Management</a>.</li><li><strong>Auto Extract Dropdown</strong>: Configure automatic extraction of figures referenced in your LaTeX source.</li></ul><h2 id="supported-file-types" tabindex="-1">Supported File Types <a class="header-anchor" href="#supported-file-types" aria-label="Permalink to &quot;Supported File Types&quot;">​</a></h2><p>TeXRA supports a range of common media types (configurable via <code>texra.files.included.mediaExtensions</code> in settings):</p><ul><li><strong>Images</strong>: <code>.png</code>, <code>.jpeg</code>, <code>.jpg</code>, <code>.gif</code>, <code>.heic</code>, <code>.heif</code>, <code>.webp</code></li><li><strong>Documents (as images/source)</strong>: <code>.pdf</code> (can be treated as images or potentially passed directly to models supporting native PDF)</li><li><strong>Audio (Experimental)</strong>: <code>.wav</code>, <code>.m4a</code>, <code>.mp3</code>, <code>.aiff</code>, <code>.aac</code>, <code>.ogg</code>, <code>.flac</code> (requires models with native audio support, currently primarily available via the <strong>experimental</strong> native Google Gemini SDK - see <a href="./configuration.html">Configuration</a>).</li></ul><div class="info custom-block"><p class="custom-block-title">PDF Handling</p><p>TeXRA prioritizes native PDF processing for models that support it (like Anthropic/Gemini/OpenAI). If a model doesn&#39;t support native PDFs, TeXRA uses external tools (GraphicsMagick/ImageMagick and Ghostscript) as a fallback to convert PDF pages to images for analysis. See the <a href="./installation.html">Installation Guide</a> for dependency details.</p></div><h2 id="quick-image-insertion-via-clipboard" tabindex="-1">Quick Image Insertion via Clipboard <a class="header-anchor" href="#quick-image-insertion-via-clipboard" aria-label="Permalink to &quot;Quick Image Insertion via Clipboard&quot;">​</a></h2><p>You can quickly add images to your TeXRA instructions by pasting directly from your clipboard:</p><ol><li><strong>Copy any image</strong> (screenshot, diagram, etc.) to your clipboard</li><li><strong>Paste in the instruction area</strong> using Ctrl/Cmd+V</li><li>The image is automatically saved and referenced as <code>[pasted_timestamp_hash.ext]</code></li><li>The Media Files section is automatically updated with the pasted image</li></ol><p>While the clipboard accepts many image formats (JPEG, PNG, GIF, WebP, BMP, SVG, TIFF, HEIC, HEIF, AVIF, PSD), the actual formats that can be processed depend on the AI model you&#39;re using. Most vision models support common formats like JPEG, PNG, GIF, and WebP. Pasted images are stored temporarily in workspace storage and cleaned up after 3 days.</p><h2 id="automatic-figure-extraction" tabindex="-1">Automatic Figure Extraction <a class="header-anchor" href="#automatic-figure-extraction" aria-label="Permalink to &quot;Automatic Figure Extraction&quot;">​</a></h2><p>TeXRA includes an &quot;Auto-extract&quot; feature to automatically identify and include figures from your input <code>.tex</code> document, reducing manual selection. This feature is accessible via the dropdown next to the Media label (<i class="codicon codicon-file-media"></i>) in the main file selection area:</p><ol><li>Click the Auto-extract toggle button (<i class="codicon codicon-wand"></i> ○<i class="codicon codicon-chevron-down"></i>) to reveal the options.</li><li>Select the types of figures to extract: <ul><li><strong>Figures</strong> (<i class="codicon codicon-file-media"></i>): Extracts standard image files (<code>.png</code>, <code>.jpg</code>, <code>.pdf</code>, etc.) referenced via <code>\\includegraphics</code>.</li><li><strong>TikZ Figures</strong> (<i class="codicon codicon-file-code"></i>): Extracts code within <code>tikzpicture</code> environments.</li></ul></li></ol><p>When enabled, TeXRA parses the input <code>.tex</code> file(s) before agent execution:</p><ul><li>Referenced image/PDF files are added to the Media Files list.</li><li>Detected <code>tikzpicture</code> code blocks are saved as separate <code>.tikz</code> files and added to the Media Files list.</li></ul><p>This ensures the agent receives all relevant visual context automatically.</p><h2 id="figure-extraction-tools-for-agents" tabindex="-1">Figure Extraction Tools for Agents <a class="header-anchor" href="#figure-extraction-tools-for-agents" aria-label="Permalink to &quot;Figure Extraction Tools for Agents&quot;">​</a></h2><p>When you are running a tool-use agent outside the UI controls, you can explicitly request figure assets via two dedicated tools:</p><ul><li><code>extract_figures</code> – scans a LaTeX file for <code>\\includegraphics</code> and related commands. It returns a newline-delimited list of referenced files and attaches each existing asset. Options: <ul><li><code>texPath</code> (required): workspace path to the primary <code>.tex</code> file.</li><li>Attachments are automatically capped to the first 20 figures to avoid overwhelming downstream providers.</li></ul></li><li><code>extract_tikz_figures</code> – extracts <code>tikzpicture</code> environments and, by default, compiles each one into a standalone PDF attachment. Options: <ul><li><code>texPath</code> (required): workspace path to the source <code>.tex</code> file.</li><li><code>compile</code> (default <code>true</code>): set to <code>false</code> to skip compilation and just receive a summary of discovered figures.</li><li>Attachments are limited to the first 12 compiled PDFs to keep responses lightweight.</li></ul></li></ul><p>Example tool call payload for <code>extract_figures</code>:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;extract_figures&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;arguments&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;texPath&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;paper/main.tex&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>The tool response includes a <code>summary</code>, formatted output listing each figure, and (when files are found) structured attachments that downstream model handlers pass to OpenAI Responses and Anthropic APIs as native file/image results. Providers without file-output support receive a textual summary with workspace paths so the agent can fetch the assets using <code>read_file</code>.</p><h2 id="manually-selecting-figures" tabindex="-1">Manually Selecting Figures <a class="header-anchor" href="#manually-selecting-figures" aria-label="Permalink to &quot;Manually Selecting Figures&quot;">​</a></h2><p>When you provide media files (manually or via auto-extract):</p><ul><li><strong>Vision Models:</strong> For models like GPT-4o or Gemini, TeXRA converts images/PDF pages to a format the model can understand (usually base64 encoded data) and includes them alongside the text prompt. This allows agents to &quot;see&quot; the figures or document pages.</li><li><strong>Audio Models (Experimental):</strong> For models supporting native audio input (primarily via the experimental native Google SDK), TeXRA uploads the audio file and provides a reference to the model. This enables agents like <code>transcribe_audio</code>.</li><li><strong>File References:</strong> Even for non-multimodal models, the <em>filenames</em> provided in the &quot;Media&quot; section can give context to the agent (e.g., &quot;Refer to figure <code>diagram.pdf</code>&quot;).</li></ul><p>Using the Media section effectively allows you to perform powerful tasks like:</p><ul><li>Asking an agent to write a caption for an image (<code>polish</code> agent).</li><li>Having an agent verify if the text description matches a figure (<code>correct</code> agent).</li><li>Generating text based on the content of images or PDFs (<code>ocr</code> agent or vision models).</li><li>Creating transcriptions from audio files (<code>transcribe_audio</code> agent).</li></ul><p>For specifics on creating and manipulating TikZ figures using the <code>draw</code> agent, please refer to the dedicated <a href="./tikz-figures.html">TikZ Figures</a> guide.</p>`,32)]))}const m=i(n,[["render",r]]);export{h as __pageData,m as default};
