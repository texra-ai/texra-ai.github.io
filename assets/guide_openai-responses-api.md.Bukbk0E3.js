import{_ as o,c as s,o as t,a6 as n}from"./chunks/framework.fkSL6LTs.js";const h=JSON.parse('{"title":"OpenAI Responses API","description":"","frontmatter":{},"headers":[],"relativePath":"guide/openai-responses-api.md","filePath":"guide/openai-responses-api.md"}'),a={name:"guide/openai-responses-api.md"};function r(i,e,p,d,c,l){return t(),s("div",null,e[0]||(e[0]=[n('<h1 id="openai-responses-api" tabindex="-1">OpenAI Responses API <a class="header-anchor" href="#openai-responses-api" aria-label="Permalink to &quot;OpenAI Responses API&quot;">​</a></h1><p>The Responses API is a recent addition to the OpenAI platform. It allows developers to build conversational tools by referencing the <code>previous_response_id</code> rather than sending the full message history on every request. TeXRA supports this API as an alternative to the Chat Completions API.</p><h2 id="key-differences" tabindex="-1">Key differences <a class="header-anchor" href="#key-differences" aria-label="Permalink to &quot;Key differences&quot;">​</a></h2><ul><li><strong>Continuations</strong>: Provide <code>previous_response_id</code> from the prior response to continue a conversation. Only the new messages are sent.</li><li><strong>Input types</strong>: Message parts use <code>input_text</code> or <code>input_image</code> objects.</li><li><strong>Output format</strong>: Instead of <code>choices</code>, text is found in <code>response.output[0].content[0].text</code> (or <code>output_text</code>).</li><li><strong>Instructions</strong>: The <code>instructions</code> parameter applies only to the current request. When using <code>previous_response_id</code>, you must resend any system instructions you want applied.</li><li><strong>No stop sequences</strong>: The Responses API does not accept a <code>stop</code> parameter. If your agent requires an end tag, handle it in post-processing rather than sending it to the API.</li></ul><p>See the <a href="https://platform.openai.com/docs/api-reference/responses" target="_blank" rel="noreferrer">OpenAI Responses documentation</a> for full details.</p><h2 id="using-with-texra" tabindex="-1">Using with TeXRA <a class="header-anchor" href="#using-with-texra" aria-label="Permalink to &quot;Using with TeXRA&quot;">​</a></h2><p>When <code>&quot;texra.model.useOpenAIResponsesAPI&quot;</code> is enabled, the extension automatically:</p><ol><li>Converts chat message parts into <code>input_text</code>/<code>input_image</code> objects.</li><li>Tracks the last <code>response.id</code> and sends it as <code>previous_response_id</code> for subsequent rounds.</li><li>Reads the returned text from <code>output_text</code> or the <code>output</code> array.</li></ol><p>This keeps requests small and simplifies conversation management.</p><p>The open-weight models <code>gpt-oss-120b</code> and <code>gpt-oss-20b</code> are available only via OpenRouter.</p>',10)]))}const f=o(a,[["render",r]]);export{h as __pageData,f as default};
