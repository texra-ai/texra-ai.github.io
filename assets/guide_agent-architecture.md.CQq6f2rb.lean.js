import{_ as d,C as c,c as u,o as s,a6 as n,j as t,b as p,a as o,t as a,w as r,G as g,a7 as f}from"./chunks/framework.fkSL6LTs.js";const L=JSON.parse('{"title":"How TeXRA Agents Work: An Overview","description":"","frontmatter":{},"headers":[],"relativePath":"guide/agent-architecture.md","filePath":"guide/agent-architecture.md"}'),m={name:"guide/agent-architecture.md"};function h(i,e,A,T,b,y){const l=c("Mermaid");return s(),u("div",null,[e[15]||(e[15]=n("",6)),t("ol",null,[e[9]||(e[9]=n("",1)),t("li",null,[e[7]||(e[7]=t("strong",null,[t("code",null,"prompts")],-1)),e[8]||(e[8]=o(": Contain text templates that TeXRA fills with your specific context (input files, instructions) to guide the LLM at different stages: ")),t("ul",null,[e[4]||(e[4]=t("li",null,[t("code",null,"systemPrompt"),o(": Sets the overall role and high-level instructions for the LLM.")],-1)),t("li",null,[e[0]||(e[0]=t("code",null,"userPrefix",-1)),e[1]||(e[1]=o(": Provides the main context, including your input file(s) (available via e.g., ")),t("code",null,a(i.INPUT_CONTENT),1),e[2]||(e[2]=o(") and the specific instruction you typed in the UI (available via ")),t("code",null,a(i.INSTRUCTION),1),e[3]||(e[3]=o(")."))]),e[5]||(e[5]=t("li",null,[t("code",null,"userRequest"),o(": Asks the LLM to perform the initial task (Round 0). Often instructs the LLM to think within "),t("code",null,"<scratchpad>"),o(" tags and then output the main content wrapped within the XML tags defined by "),t("code",null,"settings.documentTag"),o(" (e.g., "),t("code",null,"<document>...</document>"),o(").")],-1)),e[6]||(e[6]=t("li",null,[t("code",null,"userReflect"),o(': Asks the LLM to review and improve its first response (Round 1, only used if "Reflect" is enabled).')],-1))])])]),t("p",null,[e[10]||(e[10]=o("_(Prompts use Jinja2 templating. For a detailed list of available variables like ")),t("code",null,a(i.INPUT_CONTENT),1),e[11]||(e[11]=o(" and how to use them, see the ")),e[12]||(e[12]=t("a",{href:"./custom-agents.html"},"Custom Agents",-1)),e[13]||(e[13]=o(" guide.)*"))]),e[16]||(e[16]=n("",3)),(s(),p(f,null,{default:r(()=>[g(l,{id:"mermaid-83",class:"mermaid",graph:"sequenceDiagram%0A%20%20%20%20participant%20User%0A%20%20%20%20participant%20TeXRA%20UI%0A%20%20%20%20participant%20Agent%20Backend%0A%20%20%20%20participant%20LLM%20API%0A%0A%20%20%20%20User-%3E%3ETeXRA%20UI%3A%20Selects%20files%2C%20agent%2C%20instruction%2C%20model%0A%20%20%20%20User-%3E%3ETeXRA%20UI%3A%20Clicks%20Execute%0A%20%20%20%20TeXRA%20UI-%3E%3EAgent%20Backend%3A%20run(config)%0A%20%20%20%20Agent%20Backend-%3E%3EAgent%20Backend%3A%20Initialize%20(Load%20agent%20definition%2C%20read%20files)%0A%20%20%20%20Note%20over%20Agent%20Backend%3A%20Constructs%20prompt%20from%20systemPrompt%2C%20userPrefix%2C%20userRequest%20templates%20%2B%20User%20Input%0A%20%20%20%20Agent%20Backend-%3E%3ELLM%20API%3A%20Create%20Response%20(Round%200%20Prompt)%0A%20%20%20%20Note%20over%20LLM%20API%3A%20Processes%20request%20based%20on%20prompts%0A%20%20%20%20LLM%20API--%3E%3EAgent%20Backend%3A%20Response%20(Text%20%2B%20Usage%20%2B%20StopReason)%0A%20%20%20%20Agent%20Backend-%3E%3EAgent%20Backend%3A%20Process%20Response%20(Save%20*_r0_*%20output%2C%20check%20for%20continuation)%0A%20%20%20%20Agent%20Backend--%3E%3ETeXRA%20UI%3A%20Update%20ProgressBoard%20%2F%20Signal%20Completion%0A"})]),fallback:r(()=>e[14]||(e[14]=[o(" Loading... ")])),_:1})),e[17]||(e[17]=n("",14))])}const R=d(m,[["render",h]]);export{L as __pageData,R as default};
